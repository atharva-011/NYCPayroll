# Data

```{r message=FALSE, warning=FALSE}
library(httr)
library(jsonlite)
library(knitr)
library(redav)
library(mi)
library(ggplot2)
```

## Technical Description

The data that we will be using to analyze Payroll Data is from the NYC Open Data [website](https://opendata.cityofnewyork.us/) and is titled as  [**Citywide Payroll Data (Fiscal Year)**](https://data.cityofnewyork.us/City-Government/Citywide-Payroll-Data-Fiscal-Year-/k397-673e). The data set was created back in 2015 and has been constantly been updated on a annual basis (last update was on November 28,2023). It tells us about the amount of money spent on salaries and overtime pay for all municipal employees based in New York City. The data is provided by **Office of Payroll Administration (OPA)**. 

The data can be downloaded as a [JSON file](https://data.cityofnewyork.us/resource/k397-673e.json) from the website mentioned above. We make an API request with this URL, to obtain the data and convert it to a Dataframe for further processing.

```{r}
#importing the dataset
data_url <- "https://data.cityofnewyork.us/resource/k397-673e.json"

response <- httr::GET(url = data_url)
nyc_payroll_data <- jsonlite::fromJSON(content(response, "text", encoding = "UTF-8"))

print(dim(nyc_payroll_data))
```

The data consists of 5.66 million rows (essentially 5.66 million municipal employees) and 17 columns. Every row basically tells us about the employee salary, their work location, agency, base pay, overtime (if any), etc. 

```{r}
# Display columns of the dataset
kable(data.frame(Column_Names = names(nyc_payroll_data)), "markdown")

```

Presented above are the columns of the dataset.

On further examination of the data, we find that there are few inconsistencies in the data:

- The salaries for certain employees have not been mentioned per annum but on a per day or hour basis. Hence, we need to scale the data accordingly, to ensure that the data is uniform and fair comparisons can be made.

- There exist some NAN values in the data.

## Research Plan

Explain in detail how your data will enable you to answer your research questions from the introduction. 


## Missing Value Analysis

Describe any patterns you discover in missing values. If no values are missing, graphs should still be included showing that.

(suggested: 2 graphs plus commentary)
Showing count of NAN values per column

```{r}
colSums(is.na(nyc_payroll_data)) |> sort(decreasing = TRUE)
```

We see that only one column, namely `mid_init` has missing values. This feature represents the middle initial of the person under consideration. 

```{r, fig.height=18, fig.width=30}
plot_missing(nyc_payroll_data, percent = FALSE)
```

As can be seen from the above plot, there are only two patterns which can be observed in our data. The first being the complete lack of NaN values, whereas the second pattern exhibits missing values in one column only, namely, `mid_init`.

The graph on the right shows that there are nearly 300 rows exhibiting the second pattern, and about 700 points exhibiting the first, where they do not have any missing values at all.

We also get to see which columns have missing values in the form of a bar chart on top, and see that only one column falls under this category.

```{r, fig.height=11}
missing_data.frame(nyc_payroll_data) |> image()
```


This graph shows us the missing values in the entire dataset. The cells represent the actual values after scaling, defined by each row and column of the actual dataset. Higher values take on the lighter colors, whereas colors close to red represent values closer to -1. 

The values in black, indicate missing data. Here, we see that `mid_init` has missing data for nearly 300 hundred contiguous rows.

Although the absolute reason for the same is unknown, it could be possible that this data was not collected at all in that period. This can be inferred from the pattern.
